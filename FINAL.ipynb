{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMiu9Fd2Jq+mS8jxEuaIVk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ALVAROI12/F22-SDM-CKG-AI-TEACHING-A-CAR-TO-DRIVE/blob/main/FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lcbjz2nzYED"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "samples = []\n",
        "with open('/content/driving_log.csv') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    next(reader, None)\n",
        "    for line in reader:\n",
        "        samples.append(line)"
      ],
      "metadata": {
        "id": "607KoNIszgK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step2: Divide the data into training set and validation set\n",
        "train_len = int(0.8*len(samples))\n",
        "valid_len = len(samples) - train_len\n",
        "train_samples, validation_samples = data.random_split(samples, lengths=[train_len, valid_len])"
      ],
      "metadata": {
        "id": "tH6qpWDZ18dW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step3a: Define the augmentation, transformation processes, parameters and dataset for dataloader\n",
        "def augment(imgName, angle):\n",
        "  name = 'data/IMG/' + imgName.split('/')[-1]\n",
        "  current_image = cv2.imread(name)\n",
        "  current_image = current_image[65:-25, :, :]\n",
        "  if np.random.rand() < 0.5:\n",
        "    current_image = cv2.flip(current_image, 1)\n",
        "    angle = angle * -1.0  \n",
        "  return current_image, angle"
      ],
      "metadata": {
        "id": "VSBGrpFV2EG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, samples, transform=None):\n",
        "        self.samples = samples\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_samples = self.samples(index)\n",
        "        steering_angle = float(batch_samples[3])\n",
        "        center_img, steering_angle_center = augment(batch_samples[0], steering_angle)\n",
        "        left_img, steering_angle_left = augment(batch_samples[1], steering_angle + 0.4)\n",
        "        right_img, steering_angle_right = augment(batch_samples[2], steering_angle - 0.4)\n",
        "        center_img = self.transform(center_img)\n",
        "        left_img = self.transform(left_img)\n",
        "        right_img = self.transform(right_img)\n",
        "        return (center_img, steering_angle_center), (left_img, steering_angle_left), (right_img, steering_angle_right)\n",
        "      \n",
        "    def __len__(self):\n",
        "        return len(self.samples)"
      ],
      "metadata": {
        "id": "TOdG2LDf2LCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step3b: Creating generator using the dataloader to parallasize the process\n",
        "transformations = transforms.Compose([transforms.Lambda(lambda x: (x / 255.0) - 0.5)])\n",
        "\n",
        "params = {'batch_size': 32,\n",
        "          'shuffle': True,\n",
        "          'num_workers': 4}\n",
        "\n",
        "training_set = Dataset(train_samples, transformations)\n",
        "training_generator = DataLoader(training_set, **params)\n",
        "\n",
        "validation_set = Dataset(validation_samples, transformations)\n",
        "validation_generator = DataLoader(validation_set, **params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28HCEWzl4OoT",
        "outputId": "629f1b0d-11f0-4c80-f5b5-7952911f2251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NetworkLight(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(NetworkLight, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 24, 3, stride=2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(24, 48, 3, stride=2),\n",
        "            nn.MaxPool2d(4, stride=4),\n",
        "            nn.Dropout(p=0.25)\n",
        "        )\n",
        "        self.linear_layers = nn.Sequential(\n",
        "            nn.Linear(in_features=48*4*19, out_features=50),\n",
        "            nn.ELU(),\n",
        "            nn.Linear(in_features=50, out_features=10),\n",
        "            nn.Linear(in_features=10, out_features=1)\n",
        "        )\n",
        "        \n",
        "\n",
        "    def forward(self, input):\n",
        "        input = input.view(input.size(0), 3, 70, 320)\n",
        "        output = self.conv_layers(input)\n",
        "        print(output.shape)\n",
        "        output = output.view(output.size(0), -1)\n",
        "        output = self.linear_layers(output)\n",
        "        return output\n",
        " "
      ],
      "metadata": {
        "id": "lMOTqCtZ4ZCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step5: Define optimizer\n",
        "model = NetworkLight()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "9oWkzDIM4cI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step6: Check the device and define function to move tensors to that device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
        "print('device is: ', device)\n",
        "\n",
        "def toDevice(datas, device):\n",
        "  \n",
        "  imgs, angles = datas\n",
        "  return imgs.float().to(device), angles.float().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoD_0Zwm4eTe",
        "outputId": "ab4d1549-5b5b-4a6e-e794-6714899d606e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device is:  cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_epochs = 22\n",
        "for epoch in range(max_epochs):\n",
        "    model.to(device)\n",
        "    \n",
        "    # Training\n",
        "    train_loss = 0\n",
        "    model.train()\n",
        "    for local_batch, (centers, lefts, rights) in enumerate(training_generator):\n",
        "        # Transfer to GPU\n",
        "        centers, lefts, rights = toDevice(centers, device), toDevice(lefts, device), toDevice(rights, device)\n",
        "        \n",
        "        # Model computations\n",
        "        optimizer.zero_grad()\n",
        "        datas = [centers, lefts, rights]        \n",
        "        for data in datas:\n",
        "            imgs, angles = data\n",
        "#             print(\"training image: \", imgs.shape)\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, angles.unsqueeze(1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.data[0].item()\n",
        "            \n",
        "        if local_batch % 100 == 0:\n",
        "            print('Loss: %.3f '\n",
        "                % (train_loss/(local_batch+1)))\n",
        " "
      ],
      "metadata": {
        "id": "9vMcrZJr4gdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    with torch.set_grad_enabled(False):\n",
        "        for local_batch, (centers, lefts, rights) in enumerate(validation_generator):\n",
        "            # Transfer to GPU\n",
        "            centers, lefts, rights = toDevice(centers, device), toDevice(lefts, device), toDevice(rights, device)\n",
        "        \n",
        "            # Model computations\n",
        "            optimizer.zero_grad()\n",
        "            datas = [centers, lefts, rights]        \n",
        "            for data in datas:\n",
        "                imgs, angles = data\n",
        "#                 print(\"Validation image: \", imgs.shape)\n",
        "                outputs = model(imgs)\n",
        "                loss = criterion(outputs, angles.unsqueeze(1))\n",
        "                \n",
        "                valid_loss += loss.data[0].item()\n",
        "\n",
        "            if local_batch % 100 == 0:\n",
        "                print('Valid Loss: %.3f '\n",
        "                    % (valid_loss/(local_batch+1)))"
      ],
      "metadata": {
        "id": "_hZDUqir_uII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step8: Define state and save the model wrt to state\n",
        "state = {\n",
        "        'model': model.module if device == 'cuda' else model,\n",
        "        }\n",
        "\n",
        "torch.save(state, 'model.h5')"
      ],
      "metadata": {
        "id": "11AqFkU4_5gF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python drive.py model.h5"
      ],
      "metadata": {
        "id": "e2hlRqgX_9ln"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}